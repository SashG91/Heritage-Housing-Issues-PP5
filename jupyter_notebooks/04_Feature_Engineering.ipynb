{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Notebook 4: Feature Engineering**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Undertake feature engineering for regression features\n",
        "\n",
        "## Tasks\n",
        "\n",
        "* Load and inspect the data prepared during data cleaning\n",
        "* Data exploration and analysis\n",
        "* Feature engineering\n",
        "* Conclusion and steps forward\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/cleaned/train_set.csv\n",
        "* outputs/datasets/cleaned/test_set.csv\n",
        "\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* A list of variables that will be engineered\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* This notebook was informed and guided by the steps provided in the Customer Churn Walkthrough Porject.\n",
        "\n",
        "* We intend to explore the data using the CRISP-DM Data methodology.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Heritage-Housing-Issues-PP5/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Heritage-Housing-Issues-PP5'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set_path = \"outputs/datasets/cleaned/train_set.csv\"\n",
        "train_set = pd.read_csv(train_set_path)\n",
        "train_set.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_path = \"outputs/datasets/cleaned/test_set.csv\"\n",
        "test_set = pd.read_csv(test_set_path)\n",
        "test_set.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Initiate pandas profiling report to evaluate possible transformations within the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=train_set, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis and Transformation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Below I intend to use a unique function adapated from the feature-engineering lesson, to initiate feature engineering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine import transformation as vt\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def FeatureEngineeringAnalysis(df,analysis_type=None):\n",
        "  \"\"\"\n",
        "  - A fast way for feature engineering numerical and categorical variables\n",
        "  so as to decide which transformation can better transform the distribution shape \n",
        "  - Upon transformation, use a reporting tool, like ydata-profiling, to evaluate the distributions.\n",
        "\n",
        "  \"\"\"\n",
        "  check_missing_values(df)\n",
        "  allowed_types= ['numerical', 'ordinal_encoder',  'outlier_winsorizer']\n",
        "  check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
        "  list_column_transformers = define_list_column_transformers(analysis_type)\n",
        "  \n",
        "  \n",
        "  # Looping in of each variable and engineer the data according to the analysis type\n",
        "  df_feat_eng = pd.DataFrame([])\n",
        "  for column in df.columns:\n",
        "    # create additional columns (column_method) to apply the methods\n",
        "    df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
        "    for method in list_column_transformers:\n",
        "      df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
        "      \n",
        "    # Apply transformers in respectives column_transformers\n",
        "    df_feat_eng,list_applied_transformers = apply_transformers(analysis_type, df_feat_eng, column)\n",
        "\n",
        "    # For each variable, assess how the transformations have performed\n",
        "    transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng)\n",
        "\n",
        "  return df_feat_eng\n",
        "\n",
        "\n",
        "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
        "  ### Check analyis type\n",
        "  if analysis_type == None:\n",
        "    raise SystemExit(f\"Its necessary to pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
        "  if analysis_type not in allowed_types:\n",
        "      raise SystemExit(f\"analysis_type argument should be shown as one of these options: {allowed_types}\")\n",
        "\n",
        "\n",
        "def check_missing_values(df):\n",
        "  if df.isna().sum().sum() != 0:\n",
        "    raise SystemExit(\n",
        "        f\"There is a missing value in your dataset. Please correct that before getting into feature engineering.\")\n",
        "\n",
        "\n",
        "def define_list_column_transformers(analysis_type):\n",
        "  ### The suffix colummns to be set acording to analysis_type\n",
        "  if analysis_type=='numerical':\n",
        "    list_column_transformers = [\"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
        "  \n",
        "  elif analysis_type=='ordinal_encoder':\n",
        "    list_column_transformers = [\"ordinal_encoder\"]\n",
        "\n",
        "  elif analysis_type=='outlier_winsorizer':\n",
        "    list_column_transformers = ['iqr']\n",
        "\n",
        "  return list_column_transformers\n",
        "\n",
        "def apply_transformers(analysis_type, df_feat_eng, column):\n",
        "\n",
        "\n",
        "  for col in df_feat_eng.select_dtypes(include='category').columns:\n",
        "    df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
        "\n",
        "\n",
        "  if analysis_type=='numerical':\n",
        "    df_feat_eng,list_applied_transformers = FeatEngineering_Numerical(df_feat_eng,column)\n",
        "  \n",
        "  elif analysis_type=='outlier_winsorizer':\n",
        "    df_feat_eng,list_applied_transformers = FeatEngineering_OutlierWinsorizer(df_feat_eng,column)\n",
        "\n",
        "  elif analysis_type=='ordinal_encoder':\n",
        "    df_feat_eng,list_applied_transformers = FeatEngineering_CategoricalEncoder(df_feat_eng,column)\n",
        "\n",
        "  return df_feat_eng,list_applied_transformers\n",
        "\n",
        "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
        "  # For each variable, assess how the transformations are performing\n",
        "  print(f\"* Variable Analyzed: {column}\")\n",
        "  print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
        "  transformer_column = column + '_' + analysis_type\n",
        "  \n",
        "  for col in [column] + list_applied_transformers:\n",
        "    \n",
        "    if analysis_type!='ordinal_encoder':\n",
        "      DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "    \n",
        "    else:\n",
        "      print(f\"{df_feat_eng.set_index(transformer_column).groupby([transformer_column, column]).size()} \\n\")\n",
        "      if col == column: \n",
        "        DiagnosticPlots_Categories(df_feat_eng, col)\n",
        "      else:\n",
        "        DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
        "  plt.figure(figsize=(4, 3))\n",
        "  sns.countplot(data=df_feat_eng, x=col,palette=['#432371'],order = df_feat_eng[col].value_counts().index)\n",
        "  plt.xticks(rotation=90) \n",
        "  plt.suptitle(f\"{col}\", fontsize=30,y=1.05)        \n",
        "  plt.show()\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Numerical(df, variable):\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "  sns.histplot(data=df, x=variable, kde=True,element=\"step\",ax=axes[0]) \n",
        "  stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
        "  sns.boxplot(x=df[variable],ax=axes[2])\n",
        "  \n",
        "  axes[0].set_title('Histogram')\n",
        "  axes[1].set_title('QQ Plot')\n",
        "  axes[2].set_title('Boxplot')\n",
        "  fig.suptitle(f\"{variable}\", fontsize=30,y=1.05)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def FeatEngineering_CategoricalEncoder(df_feat_eng,column):\n",
        "  list_methods_worked = []\n",
        "  try:  \n",
        "    encoder= OrdinalEncoder(encoding_method='arbitrary', variables = [f\"{column}_ordinal_encoder\"])\n",
        "    df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
        "  \n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_ordinal_encoder\"],axis=1,inplace=True)\n",
        "    \n",
        "  return df_feat_eng,list_methods_worked\n",
        "\n",
        "\n",
        "def FeatEngineering_OutlierWinsorizer(df_feat_eng,column):\n",
        "  list_methods_worked = []\n",
        "\n",
        "  ### Winsorizer iqr\n",
        "  try: \n",
        "    disc=Winsorizer(\n",
        "        capping_method='iqr', tail='both', fold=1.5, variables = [f\"{column}_iqr\"])\n",
        "    df_feat_eng = disc.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_iqr\")\n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_iqr\"],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  return df_feat_eng,list_methods_worked\n",
        "\n",
        "\n",
        "def FeatEngineering_Numerical(df_feat_eng,column):\n",
        "\n",
        "  list_methods_worked = []\n",
        "\n",
        "  ### LogTransformer base e\n",
        "  try: \n",
        "    lt = vt.LogTransformer(variables = [f\"{column}_log_e\"])\n",
        "    df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_log_e\")\n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_log_e\"],axis=1,inplace=True)\n",
        "\n",
        "  ### LogTransformer base 10\n",
        "  try: \n",
        "    lt = vt.LogTransformer(variables = [f\"{column}_log_10\"],base='10')\n",
        "    df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_log_10\")\n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_log_10\"],axis=1,inplace=True)\n",
        "\n",
        "  ### ReciprocalTransformer\n",
        "  try:\n",
        "    rt = vt.ReciprocalTransformer(variables = [f\"{column}_reciprocal\"])\n",
        "    df_feat_eng =  rt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_reciprocal\")\n",
        "  except:\n",
        "    df_feat_eng.drop([f\"{column}_reciprocal\"],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "    ### PowerTransformer\n",
        "  try:\n",
        "    pt = vt.PowerTransformer(variables = [f\"{column}_power\"])\n",
        "    df_feat_eng = pt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_power\")\n",
        "  except:\n",
        "    df_feat_eng.drop([f\"{column}_power\"],axis=1,inplace=True)\n",
        "\n",
        "  ### BoxCoxTransformer\n",
        "  try:\n",
        "    bct = vt.BoxCoxTransformer(variables = [f\"{column}_box_cox\"])\n",
        "    df_feat_eng = bct.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_box_cox\")\n",
        "  except:\n",
        "    df_feat_eng.drop([f\"{column}_box_cox\"],axis=1,inplace=True)\n",
        "\n",
        "  ### YeoJohnsonTransformer\n",
        "  try:\n",
        "    yjt = vt.YeoJohnsonTransformer(variables = [f\"{column}_yeo_johnson\"])\n",
        "    df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
        "  except:\n",
        "        df_feat_eng.drop([f\"{column}_yeo_johnson\"],axis=1,inplace=True)\n",
        "\n",
        "  return df_feat_eng,list_methods_worked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Transformers to be used\n",
        "* These are the transformer that will be used and will be applied according to this order:\n",
        "\n",
        "  * Categorical Encoding\n",
        "  * Numerical Transformation\n",
        "  * Smart Correlation Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical Encoding\n",
        "\n",
        "* Replace categorical data with ordinal numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Declare a variable with the categorical variable names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_variables = list(train_set.select_dtypes(['object','category']).columns)\n",
        "categorical_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Create a dataframe from a subset of the Train set using the variable above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_categorical = train_set[categorical_variables].copy()\n",
        "df_categorical.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Apply the transformation to the variables and assess the distribution in order to select a suitable method for each variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_categorical_engineered = FeatureEngineeringAnalysis(df=df_categorical, analysis_type='ordinal_encoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Analysis of plots\n",
        "* The transformation from categorical to numerical is effective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Numerical Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Declare a variable with the numerical variable names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical_variables = list(train_set.select_dtypes(['int64','float64']).columns)\n",
        "numerical_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Create a dataframe from a subset of the Train set using the variable above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_numerical = train_set[numerical_variables].copy()\n",
        "df_numerical.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. We can apply the transformation to the variables and assess their distribution in order to select a suitable method for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_numerical_engineered = FeatureEngineeringAnalysis(df=df_numerical, analysis_type='numerical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variables Analyzed: `1stFlrSF`, `GrLivArea`, `LotArea`, `SalePrice`\n",
        "* Applied transformation:\n",
        "  * `Log e`, `Log 10`, `Reciprocal`, `Power`, `Box Cox`, `Yeo Johnson` \n",
        "* With exception of `Reciprocal` and `Power`, the applied transformations show an improvement in terms of distribution shape and QQ plot. The transformed options show characteristics of normal distribution. \n",
        "* Conclusion:\n",
        "  * `Log e`, `Log 10`, `Box Cox` and `Yeo Johnson` may be considered for numerical transformation of `1stFlrSF`, `GrLivArea`, `LotArea` and `SalePrice`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variables Analyzed: `2ndFlrSF`, `BedroomAbvGr`, `BsmtFinSF1`, `BsmtUnfSF`, `GarageArea`, `GarageYrBlt`, `TotalBsmtSF`\n",
        "* Applied transformation:\n",
        "  * `Power`, `Yeo Johnson`\n",
        "* Only 2 transformations applied were `Power` and `Yeo Johnson`.\n",
        "* Neither of the plots show an improvement in terms of distribution shape and QQ plot, since the transformed options\n",
        "don't show characteristics of normal distribution.\n",
        "* Conclusion:\n",
        "  * These variables will not be considered for numerical transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variables Analyzed: `MasVnrArea`\n",
        "* Applied transformation:\n",
        "  * `Power`, `Yeo Johnson`\n",
        "* Only 2 transformations were applied, `Power` and `Yeo Johnson`.\n",
        "* The plots for `Power` show an improvement in terms of distribution shape and QQ plot, and show characteristics of normal distribution.\n",
        "* However, `Yeo Johnson` does not show any improvement.\n",
        "* Conclusion:\n",
        "  * `Power` may be considered for numerical transformation of `MasVnrArea`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variables Analyzed: `LotFrontage`, `OverallCond`, `OverallQual`\n",
        "* Applied transformation:\n",
        "  * `Log e`, `Log 10`, `Reciprocal`, `Power`, `Box Cox`, `Yeo Johnson`\n",
        "* `Power`, `Box Cox` and `Yeo Johnson` transformations show similar results on the distribution shape and QQ plot to that of the plot before transformation.\n",
        "* `Log e`, `Log 10` and `Reciprocal` do not show improvement. \n",
        "* Conclusion:\n",
        "  * This variable will not be considered for numerical transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variable Analyzed: `OpenPorchSF`\n",
        "* Applied transformation:\n",
        "  * `Power`, `Yeo Johnson`\n",
        "* Only 2 transformations were applied, `Power` and `Yeo Johnson`.\n",
        "* The plots for `Yeo Johnson` show improvement in terms of distribution shape and QQ plot, and show characteristics of normal distribution.\n",
        "* However, `Power` does not show any improvement.\n",
        "* Conclusion:\n",
        "  * `Yeo Johnson` may be considered for numerical transformation of `OpenPorchSF`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Variable Analyzed: `YearBuilt`, `YearRemodAdd`\n",
        "* Applied transformation:\n",
        "  * `Log e`, `Log 10`, `Reciprocal`, `Power`, `Box Cox`, `Yeo Johnson`\n",
        "* Transformations on these variables offered no improvement.\n",
        "* Conclusion:\n",
        "  * These variables will not be considered for numerical transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Apply the transformation to the Train and Test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"NumericLogTransform\",vt.LogTransformer(variables=['1stFlrSF', 'LotArea', 'GrLivArea'])),\n",
        "    (\"NumericPowerTransform\",vt.PowerTransformer(variables=['MasVnrArea'])),\n",
        "    (\"NumericYeoJohnsonTransform\",vt.YeoJohnsonTransformer(variables=['OpenPorchSF']))\n",
        "    ])\n",
        "train_set = pipeline.fit_transform(train_set)\n",
        "test_set = pipeline.transform(test_set)\n",
        "\n",
        "print(\"* Numerical transformation initialized!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SmartCorrelatedSelection Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* All variables will be used for `SmartCorrelatedSelection`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Create a copy of the Train set dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop SalePrice as it will be our target to predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_temp = train_set.drop(['SalePrice'],axis=1)\n",
        "df_temp.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_smart_corr_selection = df_temp.copy()\n",
        "df_smart_corr_selection.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Create engineered variables(s) by applying the transformation(s)\n",
        "\n",
        "* Here we are Looking for groups of features that correlate amongst themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "selection_method = \"cardinality\"\n",
        "corr_method = 'spearman'\n",
        "smart_corr_selection = SmartCorrelatedSelection(variables=None, method=corr_method, threshold=0.60, selection_method=selection_method)\n",
        "\n",
        "smart_corr_selection.fit_transform(df_smart_corr_selection)\n",
        "smart_corr_selection.correlated_feature_sets_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. All possible surplus correlated features to be reomved since they would add the same information to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "smart_corr_selection.features_to_drop_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "## Conclusion and Steps to Follow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Feature Engineering Transformers\n",
        "  * Ordinal categorical encoding: `['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']`\n",
        "  * Numerical transformation:\n",
        "    * `Log e`, `Log 10`, `Box Cox` and `Yeo Johnson` may be considered for numerical transformation of `1stFlrSF`, `LotArea` and `SalePrice`.\n",
        "      * `SalePrice` will be excluded however as it will be the target of the prediction\n",
        "    * `Power` may be considered for numerical transformation of `GarageArea` and `MasVnrArea`.\n",
        "    * `Log e`, `Log 10`, `Power`, `Box Cox` and `Yeo Johnson` may be considered for numerical transformation of `GrLivArea`.\n",
        "    * `Yeo Johnson` may be considered for numerical transformation of `OpenPorchSF`.\n",
        "\n",
        "    The following transformers will be used:\n",
        "    * (\"NumericLogTransform\",vt.LogTransformer(variables=['1stFlrSF', 'GrLivArea', 'LotArea']))\n",
        "    * (\"NumericPowerTransform\",vt.PowerTransformer(variables=['GarageArea', 'MasVnrArea']))\n",
        "    * (\"NumericYeoJohnsonTransform\",vt.YeoJohnsonTransformer(variables=['OpenPorchSF']))\n",
        "  * Strongest correlated variables as per `sale_price_study notebook`:\n",
        "    * `'1stFlrSF', 'GarageArea', 'GrLivArea', 'OverallQual', 'TotalBsmtSF', 'YearBuilt'`\n",
        "  * Smart Correlation Selection:\n",
        "    * Features to be dropped: `['2ndFlrSF', 'GarageYrBlt', 'OverallQual', 'TotalBsmtSF']`\n",
        "    * Additional results from analysing different combinations of correlation method and selection method:\n",
        "      * spearman\n",
        "        * cardinality -- `['1stFlrSF', 'GrLivArea', 'GarageArea', 'YearBuilt']`\n",
        "        * drop -- `['2ndFlrSF', 'GarageYrBlt', 'OverallQual', 'TotalBsmtSF']`\n",
        "        *    variance -- `['TotalBsmtSF', '2ndFlrSF', 'GarageYrBlt', 'YearBuilt']`\n",
        "        * drop -- `['1stFlrSF', 'GarageArea', 'GrLivArea', 'OverallQual']`\n",
        "      * pearson \n",
        "        * cardinality -- `['1stFlrSF', 'GrLivArea', 'GarageArea']`\n",
        "        * drop -- `['2ndFlrSF', 'GarageYrBlt', 'TotalBsmtSF']`\n",
        "        *    variance -- `['TotalBsmtSF', '2ndFlrSF', 'GarageYrBlt']`\n",
        "        * drop -- `['1stFlrSF', 'GarageArea', 'GrLivArea']`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
