{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Notebook 5: Sales Price Prediction**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Train a ML pipeline using tuning with the best features to predict a property's sale price.\n",
        "\n",
        "## Tasks\n",
        "\n",
        "* Loading Data from cleaned data outputs\n",
        "* Creating the ML Regressor Pipelines\n",
        "* Split Train and Test sets\n",
        "* Grid Search CV - Sklearn\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* This notebook was informed and guided by the steps provided in the Customer Churn Walkthrough Porject.\n",
        "\n",
        "* We intend to explore the data using the CRISP-DM Data methodology.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Heritage-Housing-Issues-PP5/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Heritage-Housing-Issues-PP5'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load House Price Records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the house_prices_records dataset csv file into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1460, 22)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>706</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>150</td>\n",
              "      <td>548</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2003</td>\n",
              "      <td>1710</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8450</td>\n",
              "      <td>65</td>\n",
              "      <td>196</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>856</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Gd</td>\n",
              "      <td>978</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>284</td>\n",
              "      <td>460</td>\n",
              "      <td>RFn</td>\n",
              "      <td>1976</td>\n",
              "      <td>1262</td>\n",
              "      <td>TA</td>\n",
              "      <td>9600</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1262</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>3</td>\n",
              "      <td>Mn</td>\n",
              "      <td>486</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>434</td>\n",
              "      <td>608</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2001</td>\n",
              "      <td>1786</td>\n",
              "      <td>Gd</td>\n",
              "      <td>11250</td>\n",
              "      <td>68</td>\n",
              "      <td>162</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>920</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>961</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>216</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>540</td>\n",
              "      <td>642</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1998</td>\n",
              "      <td>1717</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9550</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>756</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Av</td>\n",
              "      <td>655</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>490</td>\n",
              "      <td>836</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2000</td>\n",
              "      <td>2198</td>\n",
              "      <td>Gd</td>\n",
              "      <td>14260</td>\n",
              "      <td>84</td>\n",
              "      <td>350</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1145</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1   \n",
              "0       856       854             3           No         706          GLQ  \\\n",
              "1      1262         0             3           Gd         978          ALQ   \n",
              "2       920       866             3           Mn         486          GLQ   \n",
              "3       961         0             0           No         216          ALQ   \n",
              "4      1145         0             4           Av         655          GLQ   \n",
              "\n",
              "   BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  GrLivArea KitchenQual   \n",
              "0        150         548          RFn         2003       1710          Gd  \\\n",
              "1        284         460          RFn         1976       1262          TA   \n",
              "2        434         608          RFn         2001       1786          Gd   \n",
              "3        540         642          Unf         1998       1717          Gd   \n",
              "4        490         836          RFn         2000       2198          Gd   \n",
              "\n",
              "   LotArea  LotFrontage  MasVnrArea  OpenPorchSF  OverallCond  OverallQual   \n",
              "0     8450           65         196           61            5            7  \\\n",
              "1     9600           80           0            0            8            6   \n",
              "2    11250           68         162           42            5            7   \n",
              "3     9550           60           0           35            5            7   \n",
              "4    14260           84         350           84            5            8   \n",
              "\n",
              "   TotalBsmtSF  YearBuilt  YearRemodAdd  SalePrice  \n",
              "0          856       2003          2003     208500  \n",
              "1         1262       1976          1976     181500  \n",
              "2          920       2001          2002     223500  \n",
              "3          756       1915          1970     140000  \n",
              "4         1145       2000          2000     250000  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(f\"outputs/datasets/cleaned/clean_house_price_records.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Regressor Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Here we create the ML pipeline for Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "\n",
        "### Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "### ML algorithms\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "selection_method = \"cardinality\"\n",
        "corr_method = \"spearman\"\n",
        "\n",
        "def PipelineOptimization(model):\n",
        "    pipeline_base = Pipeline([\n",
        "\n",
        "      (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                                   variables=['BsmtExposure',\n",
        "                                                              'BsmtFinType1',\n",
        "                                                              'GarageFinish',\n",
        "                                                              'KitchenQual'])),\n",
        "\n",
        "      (\"NumericLogTransform\", vt.LogTransformer(variables=['1stFlrSF',\n",
        "                                                           'LotArea',\n",
        "                                                           'GrLivArea'])),\n",
        "      (\"NumericPowerTransform\", vt.PowerTransformer(variables=['MasVnrArea'])),\n",
        "      (\"NumericYeoJohnsonTransform\",\n",
        "       vt.YeoJohnsonTransformer(variables=['OpenPorchSF'])),\n",
        "\n",
        "      (\"SmartCorrelatedSelection\",\n",
        "       SmartCorrelatedSelection(variables=None,\n",
        "                                method=corr_method,\n",
        "                                threshold=0.6,\n",
        "                                selection_method=selection_method\n",
        "                                )),\n",
        "    \n",
        "      (\"feat_scaling\", StandardScaler()),\n",
        "\n",
        "      (\"feat_selection\",  SelectFromModel(model)),\n",
        "\n",
        "      (\"model\", model),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Optimisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Custom Class for hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model = PipelineOptimization(self.models[key])\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Train and Test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Train set: (1168, 21) (1168,) \n",
            "* Test set: (292, 21) (292,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                    df.drop(['SalePrice'], axis=1),\n",
        "                                    df['SalePrice'],\n",
        "                                    test_size=0.2,\n",
        "                                    random_state=0\n",
        "                                    )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search CV - Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use default hyperparameters to find most suitable algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    'LinearRegression': {},\n",
        "    \"DecisionTreeRegressor\": {},\n",
        "    \"RandomForestRegressor\": {},\n",
        "    \"ExtraTreesRegressor\": {},\n",
        "    \"AdaBoostRegressor\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBRegressor\": {},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do a hyperparameter optimization search using default hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for LinearRegression \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 416, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 950, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/base.py\", line 918, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/encoding/ordinal.py\", line 202, in fit\n    self._check_na(X, variables_)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/encoding/base_encoder.py\", line 113, in _check_na\n    _check_optional_contains_na(X, variables)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/dataframe_checks.py\", line 292, in _check_optional_contains_na\n    raise ValueError(\nValueError: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer or set the parameter `missing_values='ignore'` when initialising this transformer.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m search \u001b[39m=\u001b[39m HyperparameterOptimizationSearch(models\u001b[39m=\u001b[39mmodels_quick_search, params\u001b[39m=\u001b[39mparams_quick_search)\n\u001b[0;32m----> 2\u001b[0m search\u001b[39m.\u001b[39;49mfit(X_train, y_train, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mr2\u001b[39;49m\u001b[39m'\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
            "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mHyperparameterOptimizationSearch.fit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     16\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[key]\n\u001b[1;32m     17\u001b[0m gs \u001b[39m=\u001b[39m GridSearchCV(model, params, cv\u001b[39m=\u001b[39mcv, n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m---> 18\u001b[0m gs\u001b[39m.\u001b[39;49mfit(X,y)\n\u001b[1;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_searches[key] \u001b[39m=\u001b[39m gs\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    877\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 416, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 950, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/base.py\", line 918, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/encoding/ordinal.py\", line 202, in fit\n    self._check_na(X, variables_)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/encoding/base_encoder.py\", line 113, in _check_na\n    _check_optional_contains_na(X, variables)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/dataframe_checks.py\", line 292, in _check_optional_contains_na\n    raise ValueError(\nValueError: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer or set the parameter `missing_values='ignore'` when initialising this transformer.\n"
          ]
        }
      ],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the results produced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "No objects to concatenate",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grid_search_summary, grid_search_pipelines \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39;49mscore_summary(sort_by\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean_score\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m grid_search_summary\n",
            "Cell \u001b[0;32mIn[7], line 44\u001b[0m, in \u001b[0;36mHyperparameterOptimizationSearch.score_summary\u001b[0;34m(self, sort_by)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mfor\u001b[39;00m p, s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params,all_scores):\n\u001b[1;32m     42\u001b[0m         rows\u001b[39m.\u001b[39mappend((row(k, s, p)))\n\u001b[0;32m---> 44\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(rows, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39msort_values([sort_by], ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmean_score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax_score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstd_score\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     46\u001b[0m columns \u001b[39m=\u001b[39m columns \u001b[39m+\u001b[39m [c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m c \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m columns]\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/pandas/core/reshape/concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    373\u001b[0m     objs,\n\u001b[1;32m    374\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    375\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    376\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    377\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    378\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    379\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    380\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    381\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    382\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    383\u001b[0m )\n\u001b[1;32m    385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/pandas/core/reshape/concat.py:429\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    426\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Client business requirement is an R2 score of at least 0.75\n",
        "* The best result is RandomForestRegressor with an average R2 score around 0.80\n",
        "* Applying an extensive search may improve the score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensive Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Conduct an extensive search on most suitable model to find the best hyperparameter configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define model and parameters, for Extensive Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"RandomForestRegressor\":RandomForestRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    \"RandomForestRegressor\":{\n",
        "        'model__n_estimators': [100,700],\n",
        "        'model__max_depth': [6,18,None],\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extensive GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for RandomForestRegressor \n",
            "\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 416, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 950, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/base.py\", line 918, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/encoding/ordinal.py\", line 202, in fit\n    self._check_na(X, variables_)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/encoding/base_encoder.py\", line 113, in _check_na\n    _check_optional_contains_na(X, variables)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/dataframe_checks.py\", line 292, in _check_optional_contains_na\n    raise ValueError(\nValueError: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer or set the parameter `missing_values='ignore'` when initialising this transformer.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m search \u001b[39m=\u001b[39m HyperparameterOptimizationSearch(models\u001b[39m=\u001b[39mmodels_search, params\u001b[39m=\u001b[39mparams_search)\n\u001b[0;32m----> 2\u001b[0m search\u001b[39m.\u001b[39;49mfit(X_train, y_train, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mr2\u001b[39;49m\u001b[39m'\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
            "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mHyperparameterOptimizationSearch.fit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     16\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[key]\n\u001b[1;32m     17\u001b[0m gs \u001b[39m=\u001b[39m GridSearchCV(model, params, cv\u001b[39m=\u001b[39mcv, n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m---> 18\u001b[0m gs\u001b[39m.\u001b[39;49mfit(X,y)\n\u001b[1;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_searches[key] \u001b[39m=\u001b[39m gs\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    877\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 416, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/pipeline.py\", line 950, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/sklearn/base.py\", line 918, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/encoding/ordinal.py\", line 202, in fit\n    self._check_na(X, variables_)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/encoding/base_encoder.py\", line 113, in _check_na\n    _check_optional_contains_na(X, variables)\n  File \"/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/feature_engine/dataframe_checks.py\", line 292, in _check_optional_contains_na\n    raise ValueError(\nValueError: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer or set the parameter `missing_values='ignore'` when initialising this transformer.\n"
          ]
        }
      ],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "No objects to concatenate",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grid_search_summary, grid_search_pipelines \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39;49mscore_summary(sort_by\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean_score\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m grid_search_summary\n",
            "Cell \u001b[0;32mIn[7], line 44\u001b[0m, in \u001b[0;36mHyperparameterOptimizationSearch.score_summary\u001b[0;34m(self, sort_by)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mfor\u001b[39;00m p, s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params,all_scores):\n\u001b[1;32m     42\u001b[0m         rows\u001b[39m.\u001b[39mappend((row(k, s, p)))\n\u001b[0;32m---> 44\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(rows, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39msort_values([sort_by], ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmean_score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax_score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstd_score\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     46\u001b[0m columns \u001b[39m=\u001b[39m columns \u001b[39m+\u001b[39m [c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m c \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m columns]\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/pandas/core/reshape/concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    373\u001b[0m     objs,\n\u001b[1;32m    374\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    375\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    376\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    377\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    378\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    379\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    380\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    381\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    382\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    383\u001b[0m )\n\u001b[1;32m    385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/pandas/core/reshape/concat.py:429\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    426\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The above extensive search improved the score, but only very slightly.\n",
        "\n",
        "* Nevertheless, the client business requirement of 0.75 has been satisfied with a score of 0.80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Establishing the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'grid_search_summary' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model \u001b[39m=\u001b[39m grid_search_summary\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m best_model\n",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_search_summary' is not defined"
          ]
        }
      ],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'grid_search_pipelines' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_parameters \u001b[39m=\u001b[39m grid_search_pipelines[best_model]\u001b[39m.\u001b[39mbest_params_\n\u001b[1;32m      2\u001b[0m best_parameters\n",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_search_pipelines' is not defined"
          ]
        }
      ],
      "source": [
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the best regressor, based on search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'grid_search_pipelines' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_regressor_pipeline \u001b[39m=\u001b[39m grid_search_pipelines[best_model]\u001b[39m.\u001b[39mbest_estimator_\n\u001b[1;32m      2\u001b[0m best_regressor_pipeline\n",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_search_pipelines' is not defined"
          ]
        }
      ],
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "## Assess feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'best_regressor_pipeline' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Following data cleaning and feature engineering, the feature shows changes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data_cleaning_feat_eng_steps \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m \u001b[39m# how many data cleaning and feature engineering does your pipeline hold?\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m columns_after_data_cleaning_feat_eng \u001b[39m=\u001b[39m (Pipeline(best_regressor_pipeline\u001b[39m.\u001b[39msteps[:data_cleaning_feat_eng_steps])\n\u001b[1;32m     10\u001b[0m                                         \u001b[39m.\u001b[39mtransform(X_train)\n\u001b[1;32m     11\u001b[0m                                         \u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m     13\u001b[0m best_features \u001b[39m=\u001b[39m columns_after_data_cleaning_feat_eng[best_regressor_pipeline[\u001b[39m'\u001b[39m\u001b[39mfeat_selection\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget_support()]\u001b[39m.\u001b[39mto_list()\n\u001b[1;32m     15\u001b[0m \u001b[39m# create DataFrame to display feature importance\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_regressor_pipeline' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Following data cleaning and feature engineering, the feature shows changes\n",
        "data_cleaning_feat_eng_steps = 5 # how many data cleaning and feature engineering does your pipeline hold?\n",
        "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
        "                                        .transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()].to_list()\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "          'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
        "          'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
        "  .sort_values(by='Importance', ascending=False)\n",
        "  )\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{best_features}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Pipeline Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error \n",
        "import numpy as np\n",
        "\n",
        "def regression_performance(X_train, y_train, X_test, y_test,pipeline):\n",
        "\tprint(\"Model Evaluation \\n\")\n",
        "\tprint(\"* Train Set\")\n",
        "\tregression_evaluation(X_train,y_train,pipeline)\n",
        "\tprint(\"* Test Set\")\n",
        "\tregression_evaluation(X_test,y_test,pipeline)\n",
        "\n",
        "def regression_evaluation(X,y,pipeline):\n",
        "  prediction = pipeline.predict(X)\n",
        "  print('R2 Score:', r2_score(y, prediction).round(3))  \n",
        "  print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))  \n",
        "  print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))  \n",
        "  print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y, prediction)).round(3))\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
        "  pred_train = pipeline.predict(X_train)\n",
        "  pred_test = pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
        "  sns.scatterplot(x=y_train , y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
        "  sns.lineplot(x=y_train , y=y_train, color='red', ax=axes[0])\n",
        "  axes[0].set_xlabel(\"Actual\")\n",
        "  axes[0].set_ylabel(\"Predictions\")\n",
        "  axes[0].set_title(\"Train Set\")\n",
        "\n",
        "  sns.scatterplot(x=y_test , y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
        "  sns.lineplot(x=y_test , y=y_test, color='red', ax=axes[1])\n",
        "  axes[1].set_xlabel(\"Actual\")\n",
        "  axes[1].set_ylabel(\"Predictions\")\n",
        "  axes[1].set_title(\"Test Set\")\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate Performance on Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Applying Regressor with Principal Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore potential values for PCA n_components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = PipelineOptimization(model=LinearRegression())\n",
        "pipeline_pca = Pipeline(pipeline.steps[:6])\n",
        "df_pca = pipeline_pca.fit_transform(df.drop(['SalePrice'],axis=1))\n",
        "\n",
        "print(df_pca.shape,'\\n', type(df_pca))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply Principal Component Analysis separately to the scaled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "n_components = 17\n",
        "\n",
        "def pca_components_analysis(df_pca,n_components): \n",
        "    pca = PCA(n_components=n_components).fit(df_pca)\n",
        "    x_PCA = pca.transform(df_pca) # array with transformed PCA\n",
        "\n",
        "    ComponentsList = [\"Component \" + str(number) for number in range(n_components)]\n",
        "    dfExplVarRatio = pd.DataFrame(\n",
        "        data= np.round(100 * pca.explained_variance_ratio_ ,3),\n",
        "        index=ComponentsList,\n",
        "        columns=['Explained Variance Ratio (%)'])\n",
        "\n",
        "    dfExplVarRatio['Accumulated Variance'] = dfExplVarRatio['Explained Variance Ratio (%)'].cumsum() \n",
        "\n",
        "    PercentageOfDataExplained = dfExplVarRatio['Explained Variance Ratio (%)'].sum()\n",
        "\n",
        "    print(f\"* The {n_components} components explain {round(PercentageOfDataExplained,2)}% of the data \\n\")\n",
        "    plt.figure(figsize=(12,5))\n",
        "    sns.lineplot(data=dfExplVarRatio,  marker=\"o\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(np.arange(0, 110, 10))\n",
        "    plt.show()\n",
        "\n",
        "pca_components_analysis(df_pca=df_pca,n_components=n_components)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_components = 9\n",
        "pca_components_analysis(df_pca=df_pca,n_components=n_components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rewrite ML Pipeline for Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineOptimization(model):\n",
        "    pipeline_base = Pipeline([\n",
        "\n",
        "      (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                                   variables=['BsmtExposure',\n",
        "                                                              'BsmtFinType1',\n",
        "                                                              'GarageFinish',\n",
        "                                                              'KitchenQual'])),\n",
        "\n",
        "      (\"NumericLogTransform\", vt.LogTransformer(variables=['1stFlrSF',\n",
        "                                                           'LotArea',\n",
        "                                                           'GrLivArea'])),\n",
        "      (\"NumericPowerTransform\", vt.PowerTransformer(variables=['GarageArea',\n",
        "                                                               'MasVnrArea'])),\n",
        "      (\"NumericYeoJohnsonTransform\",\n",
        "       vt.YeoJohnsonTransformer(variables=['OpenPorchSF'])),\n",
        "\n",
        "      (\"SmartCorrelatedSelection\",\n",
        "       SmartCorrelatedSelection(variables=None,\n",
        "                                method=corr_method,\n",
        "                                threshold=0.6,\n",
        "                                selection_method=selection_method\n",
        "                                )),\n",
        "\n",
        "      (\"feat_scaling\", StandardScaler()),\n",
        "\n",
        "      (\"PCA\", PCA(n_components=n_components, random_state=0)),\n",
        "\n",
        "      (\"model\", model),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search CV  Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use standard hyperparameters to find most suitable model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    'LinearRegression': {},\n",
        "    \"DecisionTreeRegressor\": {},\n",
        "    \"RandomForestRegressor\": {},\n",
        "    \"ExtraTreesRegressor\": {},\n",
        "    \"AdaBoostRegressor\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBRegressor\": {},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can do a quick optimization search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quick_search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "quick_search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Do extensive search on most feasible model to helps locate the best hyperparameter configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define model and parameters for extensive search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "models_search = {\n",
        "    \"RandomForestRegressor\":RandomForestRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    \"RandomForestRegressor\":{\n",
        "        'model__n_estimators': [100,700],\n",
        "        'model__max_depth': [6,18,None],\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extensive GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameters for best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_pipelines[best_model].best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the best regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_regressor_pipeline_pca = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline_pca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Regressor on Train and Tests datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline_pca)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test,\n",
        "                            best_regressor_pipeline_pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regressor Model Analysis findings\n",
        "\n",
        "* A Regressor model was chosen to predict sale price for a given property.\n",
        "\n",
        "* Both feature selection and PCA produced close results and met business requirement 1. Despite by a small margin, feature \n",
        "selection performed better. Therefore, the best pipeline to use will be that of feature selection in this case. \n",
        "\n",
        "* Feature selection achieved an R2 Score: 0.97 on the train set and an R2 Score: 0.78 on the test set.\n",
        "\n",
        "* The client requirement is for an R2 Score of 0.75\\n\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Features for the Subsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.filter(best_features)\n",
        "X_test = X_test.filter(best_features)\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\", X_test.shape, y_test.shape)\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Refit pipeline with optimal determined features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rewrite Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineOptimization(model):\n",
        "    pipeline_base = Pipeline([\n",
        "\n",
        "      (\"NumericLogTransform\", vt.LogTransformer(variables=['1stFlrSF',\n",
        "                                                           'GrLivArea'])),\n",
        "\n",
        "      (\"feat_scaling\", StandardScaler()),\n",
        "\n",
        "      (\"model\", model),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search CV  Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At this stage we can use the same model from the previous GridCV search above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the best parameters from the previous GridCV search above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add the above parameters in manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_search = {\n",
        "    'RandomForestRegressor':  {\n",
        "        'model__max_depth': [18],\n",
        "        'model__n_estimators': [100]\n",
        "        }\n",
        "    }\n",
        "params_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the best regressor pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assess feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_cleaning_feat_eng_steps = 1 # how many data cleaning and feature engineering does your pipeline have?\n",
        "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
        "                                        .transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "          'Feature': columns_after_data_cleaning_feat_eng,\n",
        "          'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
        "  .sort_values(by='Importance', ascending=False)\n",
        "  )\n",
        "\n",
        "# The most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{best_features}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate Performance on Train and Test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save datasets and models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will generate the following files\n",
        "\n",
        "* Train set\n",
        "* Test set\n",
        "* Modeling pipeline\n",
        "* features importance plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "version = 'v3'\n",
        "file_path = f'outputs/ml_pipeline/predict_salesprice/{version}'\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Set : Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y_train.shape)\n",
        "y_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Set: Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_test.shape)\n",
        "X_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y_test.shape)\n",
        "y_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelling pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_regressor_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(value=best_regressor_pipeline, filename=f\"{file_path}/best_regressor_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Importance Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feature_importance.to_csv(f\"{file_path}/feature_importance.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
        "plt.savefig(f'{file_path}/feature_importance.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
        "pred_train = best_regressor_pipeline.predict(X_train)\n",
        "pred_test = best_regressor_pipeline.predict(X_test)\n",
        "alpha_scatter=0.5\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
        "sns.scatterplot(x=y_train , y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
        "sns.lineplot(x=y_train , y=y_train, color='red', ax=axes[0])\n",
        "axes[0].set_xlabel(\"Actual\")\n",
        "axes[0].set_ylabel(\"Predictions\")\n",
        "axes[0].set_title(\"Train Set\")\n",
        "\n",
        "sns.scatterplot(x=y_test , y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
        "sns.lineplot(x=y_test , y=y_test, color='red', ax=axes[1])\n",
        "axes[1].set_xlabel(\"Actual\")\n",
        "axes[1].set_ylabel(\"Predictions\")\n",
        "axes[1].set_title(\"Test Set\")\n",
        "\n",
        "plt.savefig(f'{file_path}/regression_evaluation_plots.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following files were generated:\n",
        "\n",
        "* Train set\n",
        "* Test set\n",
        "* Modeling pipeline\n",
        "* features importance plot\n",
        "\n",
        "* A Regressor model was chosen to predict sale price for a given property suggesting that feature selection and PCA produced close results that meet the business requirements. However, with a small margin we found that feature selction had better performance and was therefore chosen as the best pipeline for our buiness case. The following results were produce to meet our targets:\n",
        "\n",
        "* Feature selection achieved an R2 Score: 0.97 on the train set and an R2 Score: 0.78 on the test set.\n",
        "\n",
        "* The client requirement is for an R2 Score of 0.75\\n\"\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
